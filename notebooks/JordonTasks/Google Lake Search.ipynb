{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2973aea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib\n",
    "from urllib import request\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import pandas as pd\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe2f4c2",
   "metadata": {},
   "source": [
    "## The first box allows you to adjust the parameters of the code. After you're done editing those, run all other cells.  The code only does 50 searches at a time, but I'm working on making it a loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "78e6e44e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####  FOR ALL INPUTS\n",
    "\n",
    "# API Search Engine URL:\n",
    "# NOTE: You probably won't change this, unless you're using a different search engine with the API\n",
    "APIurl = 'https://www.googleapis.com/customsearch/v1?key=AIzaSyBZl683A8IrcIiwPLT4gchHo2DdqcgujFs&cx=643b7acb0336d498a&q=\"'\n",
    "\n",
    "# input file path to use:\n",
    "inputfile = '/home/hboi-ouri/Projects/NASA_ProjectExp/outputs/JBTask/Google Lake Search Task/LakeListInput.csv'\n",
    "\n",
    "#0-50 or 50-100:\n",
    "first = 50\n",
    "last = 100\n",
    "\n",
    "# search terms in addition to the lake name in the input CSV. \n",
    "# RULES FOR ADDING MORE SEARCH TERMS:\n",
    "#  1. If you aren't adding anything, leave the string completely blank\n",
    "#  2. If you will add something, start the string with a + sign, replace ALL spaces with a + sign, \n",
    "#     surround your additional text with \"\", and DON'T use apostrophes '\n",
    "#  3. Search term modifiers are standard with Google. For example: AND, OR, *\n",
    "addsearchterms = '\"Benthic+flux\"+\"Algae+bloom\"'\n",
    "\n",
    "# output file path to use:\n",
    "outputfile = '/home/hboi-ouri/Projects/NASA_ProjectExp/outputs/JBTask/Google Lake Search Task/LakeListOutput('+addsearchterms+').csv'\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d2059e91",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51 Wheeler Lake\n",
      "52 Amistad Lake\n",
      "53 Klamath Lake\n",
      "54 Tustumena Lake\n",
      "55 Lake Moultrie\n",
      "56 Lake Winnibigoshish\n",
      "57 Lake Barkley\n",
      "58 Lake Sharpe\n",
      "59 American Falls Reservoir\n",
      "60 Lake Hartwell\n",
      "61 Truman Reservoir\n",
      "62 Lake of the Ozarks\n",
      "63 Oneida Lake\n",
      "64 Lake Cumberland\n",
      "65 Kerr Lake\n",
      "66 Calcasieu Lake\n",
      "67 Lake Murray\n",
      "68 Grand Lake * the Cherokees\n",
      "69 Lake Koocanusa\n",
      "70 Lake George\n",
      "71 Lake Winnipesaukee\n",
      "72 Bull Shoals Lake\n",
      "73 Walter F. George Lake\n",
      "74 Lake Martin\n",
      "75 Clear Lake\n",
      "76 Robert S. Kerr Lake\n",
      "77 Seneca Lake\n",
      "78 Pickwick Lake\n",
      "79 Table Rock Lake\n",
      "80 Cayuga Lake\n",
      "81 Flaming Gorge Reservoir\n",
      "82 Richland-Chambers Reservoir\n",
      "83 Lake Vermilion\n",
      "84 Lake Ouachita\n",
      "85 Lake Mattamuskeet\n",
      "86 Watts Bar Lake\n",
      "87 Lake Wallula\n",
      "88 Lake Lanier\n",
      "89 Lake Tawakoni\n",
      "90 Elephant Butte Lake\n",
      "91 Chickamauga Lake\n",
      "92 Grenada Lake\n",
      "93 Lake Kissimmee\n",
      "94 Lake Dardanelle\n",
      "95 Norris Lake\n",
      "96 Canyon Ferry Lake\n",
      "97 Lake Chelan\n",
      "98 Cedar Creek Lake\n",
      "99 Lake Norman\n",
      "100 Sardis Lake\n"
     ]
    }
   ],
   "source": [
    "# Takes CSV input file and prints list of lakes to be searched and their list index\n",
    "\n",
    "\n",
    "lakeinput = pd.read_csv(inputfile, encoding='UTF-8', keep_default_na=False)\n",
    "\n",
    "indexlist = list(lakeinput['Index'][first:last])\n",
    "lakelist = list(lakeinput['Lake'][first:last])\n",
    "\n",
    "listsize = len(indexlist)\n",
    "\n",
    "for (lakes, indeces) in zip(lakelist, indexlist):\n",
    "    print(indeces, lakes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5ac9111e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes each lake in lakelist, uses the API to determine the number of search results for each lake, \n",
    "#  then turns the search results into a list with the same order as the lakes\n",
    "    \n",
    "    \n",
    "resultnumber = []\n",
    "\n",
    "for lake in lakelist:\n",
    "    lake = lake.replace(' ','+')\n",
    "    url = APIurl+lake+'\"'+addsearchterms+'&alt=json&fields=queries(request(totalResults))'\n",
    "    url = 'https://www.googleapis.com/customsearch/v1?key=AIzaSyBZl683A8IrcIiwPLT4gchHo2DdqcgujFs&cx=643b7acb0336d498a&q=\"'+lake+'\"'+addsearchterms+'&alt=json&fields=queries(request(totalResults))'\n",
    "    html = request.urlopen(url).read()\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    site_json=json.loads(soup.text)\n",
    "    \n",
    "    resultnumber.append([d.get('totalResults') for d in site_json['queries']['request'] if d.get('totalResults')])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f59abd99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2ea34775",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Turns the indeces, lake names, and result number into a list of lists, with each item corresponding\n",
    "#   to one lake or entry\n",
    "\n",
    "if first == 0:\n",
    "    \n",
    "    indexlistreal = ['Index']\n",
    "    for index in indexlist:\n",
    "        indexlistreal.append(index)\n",
    "\n",
    "    lakelistreal = ['Lake']\n",
    "    for lake in lakelist:\n",
    "        lakelistreal.append(lake)\n",
    "\n",
    "    resultnumberreal = ['Number of Results, '+'(' + addsearchterms +')']\n",
    "    for item in resultnumber:\n",
    "        if bool(item) == False:\n",
    "            resultnumberreal.append('0')\n",
    "        else:\n",
    "            resultnumberreal.append(item[0])\n",
    "\n",
    "            \n",
    "    field_names = ['Index','Lake','Number of Results, '+'(' + addsearchterms +')']\n",
    "    with open(outputfile, 'a') as csv_file:\n",
    "        dict_object = csv.DictWriter(csv_file, fieldnames=field_names) \n",
    "        for i, index in enumerate(indexlistreal[0:51]):\n",
    "            dict_object.writerow({\"Index\": index, \"Lake\": lakelistreal[i], 'Number of Results, '+'(' + addsearchterms +')': resultnumberreal[i]})\n",
    "\n",
    "                \n",
    "else:\n",
    "    indexlistreal = []\n",
    "    for index in indexlist:\n",
    "        indexlistreal.append(index)\n",
    "\n",
    "    lakelistreal = []\n",
    "    for lake in lakelist:\n",
    "        lakelistreal.append(lake)\n",
    "\n",
    "    resultnumberreal = []\n",
    "    for item in resultnumber:\n",
    "        if bool(item) == False:\n",
    "            resultnumberreal.append('0')\n",
    "        else:\n",
    "            resultnumberreal.append(item[0])\n",
    "\n",
    "            \n",
    "    field_names = ['Index','Lake','Number of Results, '+'(' + addsearchterms +')']\n",
    "    with open(outputfile, 'a') as csv_file:\n",
    "        dict_object = csv.DictWriter(csv_file, fieldnames=field_names) \n",
    "        for i, index in enumerate(indexlistreal[0:50]):\n",
    "            dict_object.writerow({\"Index\": index, \"Lake\": lakelistreal[i], 'Number of Results, '+'(' + addsearchterms +')': resultnumberreal[i]})\n",
    "\n",
    "              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11fd2d8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a40e6be9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b40a8e0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac6beed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f249444",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
